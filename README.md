## Facial Expression Recognition using Convolutional Neural Networks

### Description

This repository contains code for training a Convolutional Neural Network (CNN) to recognize facial expressions based on images. The dataset consists of images of faces annotated with different emotions, such as happiness, sadness, anger, and surprise.

### Data Preprocessing

The code begins by cloning the dataset repository from GitHub and reading the annotation file (legend.csv) containing information about the images and their corresponding emotions. It preprocesses the data by organizing the images into training and testing directories based on the specified split size.

### Data Augmentation

To increase the diversity of the training data and improve the model's generalization, the script utilizes data augmentation techniques such as rotation, zooming, and horizontal flipping.

### Model Architecture

The CNN model architecture is defined using the Keras Sequential API. It consists of multiple convolutional layers followed by max-pooling layers for feature extraction. The model concludes with fully connected layers and a softmax activation function for multi-class classification.

### Training

The model is trained using the training data generated by the ImageDataGenerator. Early stopping is employed as a callback to prevent overfitting and improve efficiency. The training process monitors the validation accuracy and stops training if no improvement is observed after a certain number of epochs.

### Evaluation

After training, the model's performance is evaluated on a separate test dataset. Performance metrics such as accuracy and loss are computed to assess the model's effectiveness in recognizing facial expressions.

